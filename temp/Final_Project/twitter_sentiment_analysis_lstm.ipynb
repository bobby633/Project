{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e9af0762-88ad-444a-98d6-b60ff39fb1f7",
        "_uuid": "e323ac66-f138-4c99-84e7-ffc2d736df95",
        "id": "It-QrenxDvzh",
        "trusted": true
      },
      "source": [
        "## Installing and importing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ad397e61-b81d-48bc-bb0c-471762f5620e",
        "_uuid": "f5296f63-a4d8-448f-8a66-4a5a74844b73",
        "id": "NQyYyJuSDvzh",
        "trusted": true
      },
      "source": [
        "To fetch tweets from twitter, we need to install the tweepy library. We will be using this package to pull tweets on which our model will make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76f1f3d0-b6fe-44a9-993e-ecfe7f108944",
        "_uuid": "c0e8bf21-9fc1-464b-a11b-6bdf4b0f9fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:48:15.342066Z",
          "iopub.status.busy": "2021-06-15T13:48:15.341787Z",
          "iopub.status.idle": "2021-06-15T13:48:22.030557Z",
          "shell.execute_reply": "2021-06-15T13:48:22.028518Z",
          "shell.execute_reply.started": "2021-06-15T13:48:15.342038Z"
        },
        "id": "tFxmFj5ADvzj",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "37dbdc20-7077-428c-cd68-a216c580f875",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import os\n",
        "import tweepy as tw #for accessing Twitter API\n",
        "\n",
        "\n",
        "#For Preprocessing\n",
        "import re    # RegEx for removing non-letter characters\n",
        "import nltk  #natural language processing\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "# For Building the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "#For data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.plotting.backend = \"plotly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "49547739-db4d-4559-b6d2-600ecd225d3e",
        "_uuid": "88e14970-da9b-4403-af5e-c631eede9c19",
        "id": "Se1Eazh-Dvzk",
        "trusted": true
      },
      "source": [
        "### Cleaning and prepping dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "debf7898-99e6-442b-8102-b8414809d8e3",
        "_uuid": "a89e4673-96aa-4b2f-916c-6c6bce257519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:48:22.033097Z",
          "iopub.status.busy": "2021-06-15T13:48:22.032452Z",
          "iopub.status.idle": "2021-06-15T13:48:22.675333Z",
          "shell.execute_reply": "2021-06-15T13:48:22.673006Z",
          "shell.execute_reply.started": "2021-06-15T13:48:22.033055Z"
        },
        "id": "M4HPaCk0Dvzk",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6fbc5c93-a723-4f7f-80e2-ad493ebe5c49",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load Tweet dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4vd3piLvA0o"
      },
      "source": [
        "###Getting Data And Combining Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QbbvLX8MHjgN",
        "outputId": "e2ccdbd6-0bc9-424d-cd43-5276ac478887"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04f81b93-7e1d-4683-8ddf-21d06212f322\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04f81b93-7e1d-4683-8ddf-21d06212f322')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04f81b93-7e1d-4683-8ddf-21d06212f322 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04f81b93-7e1d-4683-8ddf-21d06212f322');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          clean_text  category\n",
              "0  when modi promised “minimum government maximum...  Negative\n",
              "1  talk all the nonsense and continue all the dra...   Neutral\n",
              "2  what did just say vote for modi  welcome bjp t...  Positive\n",
              "3  asking his supporters prefix chowkidar their n...  Positive\n",
              "4  answer who among these the most powerful world...  Positive"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#first one\n",
        "data1 = pd.read_csv(r\"/content/drive/MyDrive/files/Twitter_Data.csv\")\n",
        "#second dataset\n",
        "data2 = pd.read_csv(r'/content/drive/MyDrive/files/apple-twitter-sentiment-texts.csv')\n",
        "data2 = data2.rename(columns={'text': 'clean_text', 'sentiment':'category'})\n",
        "data2['category'] = data2['category'].map({-1: -1.0, 0: 0.0, 1:1.0})\n",
        "#third dataset\n",
        "data3 = pd.read_csv('/content/drive/MyDrive/files/finalSentimentdata2.csv')\n",
        "data3 = data3.rename(columns={'text': 'clean_text', 'sentiment':'category'})\n",
        "data3['category'] = data3['category'].map({'sad': -1.0, 'anger': -1.0, 'fear': -1.0, 'joy':1.0})\n",
        "data3 = data3.drop(['Unnamed: 0'], axis=1)\n",
        "#fouth dataset\n",
        "data4 = pd.read_csv('/content/drive/MyDrive/files/Tweets.csv')\n",
        "data4 = data4.rename(columns={'text': 'clean_text', 'airline_sentiment':'category'})\n",
        "data4['category'] = data4['category'].map({'negative': -1.0, 'neutral': 0.0, 'positive':1.0})\n",
        "data4 = data4[['category','clean_text']]\n",
        "#combine\n",
        "df = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
        "# drop missing rows\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df['category'] = df['category'].map({-1.0:'Negative', 0.0:'Neutral', 1.0:'Positive'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "de0f402f-09e1-4bc6-bb6a-afc89ee55ad0",
        "_uuid": "f03fa6a3-85de-4c49-8e0f-eebc3abb0f74",
        "id": "6P65c1yPDvzq",
        "trusted": true
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "13bf9b06-9a96-4e39-b3dd-8c24d848c2c2",
        "_uuid": "b452e7a7-8132-4951-a932-d007b3955870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:48:51.533906Z",
          "iopub.status.busy": "2021-06-15T13:48:51.533574Z",
          "iopub.status.idle": "2021-06-15T13:48:51.553512Z",
          "shell.execute_reply": "2021-06-15T13:48:51.552693Z",
          "shell.execute_reply.started": "2021-06-15T13:48:51.533869Z"
        },
        "id": "rim_FaEYDvzq",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b347f7de-7ca9-43a2-f381-67b3120abec7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original tweet -> when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n",
            "\n",
            "Processed tweet -> ['modi', 'promis', 'minimum', 'govern', 'maximum', 'govern', 'expect', 'begin', 'difficult', 'job', 'reform', 'state', 'take', 'year', 'get', 'justic', 'state', 'busi', 'exit', 'psu', 'templ']\n"
          ]
        }
      ],
      "source": [
        "def tweet_to_words(tweet):\n",
        "    ''' Convert tweet text into a sequence of words '''\n",
        "    \n",
        "    # convert to lowercase\n",
        "    text = tweet.lower()\n",
        "    # remove non letters\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
        "    # tokenize\n",
        "    words = text.split()\n",
        "    # remove stopwords\n",
        "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "    # apply stemming\n",
        "    words = [PorterStemmer().stem(w) for w in words]\n",
        "    # return list\n",
        "    return words\n",
        "\n",
        "print(\"\\nOriginal tweet ->\", df['clean_text'][0])\n",
        "print(\"\\nProcessed tweet ->\", tweet_to_words(df['clean_text'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fdd4e291-fc5e-436a-bae3-fdde3fad279f",
        "_uuid": "792352af-397b-42b1-bd22-97a83548c929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:48:51.555414Z",
          "iopub.status.busy": "2021-06-15T13:48:51.555058Z",
          "iopub.status.idle": "2021-06-15T13:56:56.429724Z",
          "shell.execute_reply": "2021-06-15T13:56:56.428932Z",
          "shell.execute_reply.started": "2021-06-15T13:48:51.555381Z"
        },
        "id": "yIePgRTQDvzq",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8fc06656-e0f4-4c62-ea40-e202aecc35ea",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-948d2e041392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply data processing to each tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_to_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-8260e889a451>\u001b[0m in \u001b[0;36mtweet_to_words\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# apply stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-8260e889a451>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# apply stemming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0m\u001b[1;32m     23\u001b[0m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such file or directory: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Apply data processing to each tweet\n",
        "X = list(map(tweet_to_words, df['clean_text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f9ff9b12-980d-4a0c-b205-7abba133ba3e",
        "_uuid": "a69f5a61-e641-4d50-be8a-561ffdd13aeb",
        "id": "oYC7kK1sDvzr",
        "trusted": true
      },
      "source": [
        "### Train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9e9e40f-3610-4d2f-87d3-a124082b688a",
        "_uuid": "3eb577ca-80df-496b-91e1-ba0aab21fe11",
        "execution": {
          "iopub.execute_input": "2021-06-15T13:56:56.736192Z",
          "iopub.status.busy": "2021-06-15T13:56:56.735579Z",
          "iopub.status.idle": "2021-06-15T13:57:00.775493Z",
          "shell.execute_reply": "2021-06-15T13:57:00.774712Z",
          "shell.execute_reply.started": "2021-06-15T13:56:56.736152Z"
        },
        "id": "xeTKrZoqDvzr",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Encode target labels\n",
        "label = LabelEncoder()\n",
        "Y = label.fit_transform(df['category'])\n",
        "\n",
        "y = pd.get_dummies(df['category'])\n",
        "training_x, testing_x, training_y, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "training_x, X_validation, training_y, y_validation = train_test_split(training_x, training_y, test_size=0.25, random_state=1)\n",
        "v_Size = 5000\n",
        "\n",
        "c_v = CountVectorizer(max_features=v_Size,preprocessor=lambda x: x, toke=lambda x: x) \n",
        "\n",
        "# Fit the training data\n",
        "training_x = c_v.fit_transform(training_x).toarray()\n",
        "\n",
        "# Transform testing data\n",
        "testing_x = c_v.transform(testing_x).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fa0fa00f-3b2e-4bf3-9e56-a3c0e99a5033",
        "_uuid": "e0790578-2f97-45d2-ac1b-eca2dac01166",
        "id": "DJ_OpVFmDvzs",
        "trusted": true
      },
      "source": [
        "training_xtraining_xtraining_### Tokenizing & Paddingvdfffffdftraining_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee7d87c0-f428-47d0-92cf-4e3b157d83eb",
        "_uuid": "09fe6021-b3ac-419c-ab3b-3a1f76379a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:57:00.922444Z",
          "iopub.status.busy": "2021-06-15T13:57:00.9221Z",
          "iopub.status.idle": "2021-06-15T13:57:10.389152Z",
          "shell.execute_reply": "2021-06-15T13:57:10.387288Z",
          "shell.execute_reply.started": "2021-06-15T13:57:00.92241Z"
        },
        "id": "BrK2vypTDvzs",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6ab137ea-634c-485d-9b09-36bc5133ec2f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Tokenization & Padding \n",
            " when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n",
            "After Tokenization & Padding \n",
            " [  41    1  349   73 1911 1180   44 2465    2 1259  219    2  236   32\n",
            "  165  102   53   55 1184  236   50    3    6  533    3   50 3833    3\n",
            " 3077    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_words = 5000\n",
        "max_len=50\n",
        "\n",
        "def tokenize_pad_sequences(text):\n",
        "    '''\n",
        "    This function tokenize the input text into sequnences of intergers and then\n",
        "    pad each sequence to the same length\n",
        "    '''\n",
        "    # Text tokenization\n",
        "    toke = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
        "    toke.fit_on_texts(text)\n",
        "    # Transforms text to a sequence of integers\n",
        "    X = toke.texts_to_sequences(text)\n",
        "    # Pad sequences to the same length\n",
        "    X = pad_sequences(X, padding='post', maxlen=max_len)\n",
        "    # return sequences\n",
        "    return X, toke\n",
        "\n",
        "X, toke = tokenize_pad_sequences(df['clean_text'])\n",
        "\n",
        "\n",
        "\n",
        "# saving\n",
        "with open('/content/drive/MyDrive/files/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(toke, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# loading\n",
        "with open('/content/drive/MyDrive/files/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "918b178c-362d-4307-950c-67f205eadc68",
        "_uuid": "3428c844-00ef-4add-b27c-794d7aeb5c9b",
        "id": "fut83zHiDvzs",
        "trusted": true
      },
      "source": [
        "### Saving tokenized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53611a76-f3fe-4a8b-a86e-a956ad8dc2b3",
        "_uuid": "0dd5da2a-01b2-4697-a201-736d6a9bd9f1",
        "execution": {
          "iopub.execute_input": "2021-06-15T13:57:10.390829Z",
          "iopub.status.busy": "2021-06-15T13:57:10.390514Z",
          "iopub.status.idle": "2021-06-15T13:57:10.662767Z",
          "shell.execute_reply": "2021-06-15T13:57:10.661979Z",
          "shell.execute_reply.started": "2021-06-15T13:57:10.390795Z"
        },
        "id": "Z1EveG3XDvzs",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "17d33b73-9e80-45f3-8dc2-d33353ac7fc7",
        "_uuid": "761a0192-6c66-44b1-988f-530dfc4ac8ce",
        "id": "bBDIefDlDvzs",
        "trusted": true
      },
      "source": [
        "### Train & Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab4d79f8-27f4-4384-866a-280442941ef7",
        "_uuid": "8218591d-f858-4e1f-a877-10e74f0885f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:57:10.66547Z",
          "iopub.status.busy": "2021-06-15T13:57:10.664774Z",
          "iopub.status.idle": "2021-06-15T13:57:10.905583Z",
          "shell.execute_reply": "2021-06-15T13:57:10.9044Z",
          "shell.execute_reply.started": "2021-06-15T13:57:10.665432Z"
        },
        "id": "ZD55mRZwDvzs",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "3909831e-3ced-4667-85f1-e9310fd98b1a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set -> (109397, 50) (109397, 3)\n",
            "Validation Set -> (36466, 50) (36466, 3)\n",
            "Test Set -> (36466, 50) (36466, 3)\n"
          ]
        }
      ],
      "source": [
        "y = pd.get_dummies(df['category'])\n",
        "training_x, testing_x, training_y, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "training_x, X_validation, training_y, y_validation = train_test_split(training_x, training_y, test_size=0.25, random_state=1)\n",
        "print('Train Set ->', training_x.shape, training_y.shape)\n",
        "print('Validation Set ->', X_validation.shape, y_validation.shape)\n",
        "print('Test Set ->', testing_x.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "819dd6c6-7269-4ebd-b130-089311a92c26",
        "_uuid": "f4466e64-4f6a-4868-b430-153d7511a83a",
        "id": "PX0KuC60Dvzt",
        "trusted": true
      },
      "source": [
        "## Bidirectional LSTM Using NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34db76fb-fc02-4aa9-86ef-88d30cb5aa01",
        "_uuid": "bb98be32-1c7a-442a-bd28-7bf3a01b6050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:57:10.919564Z",
          "iopub.status.busy": "2021-06-15T13:57:10.919179Z",
          "iopub.status.idle": "2021-06-15T13:57:13.675214Z",
          "shell.execute_reply": "2021-06-15T13:57:13.674327Z",
          "shell.execute_reply.started": "2021-06-15T13:57:10.919531Z"
        },
        "id": "tT61bwTCDvzt",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d59bf1c1-1d0b-4e5b-e183-07fe5f497d64",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import datasets\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import History\n",
        "\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "vocab_size = 5000\n",
        "e_size = 32\n",
        "epochs=20\n",
        "learning_rate = 0.1\n",
        "d_rate = learning_rate / epochs\n",
        "momentum = 0.8\n",
        "\n",
        "Stochastic_Gradient_Descent = SGD(learning_rate=learning_rate, momentum=momentum, decay=d_rate, nesterov=False)\n",
        "# Build model\n",
        "model= Sequential()\n",
        "model.add(Embedding(vocab_size, e_size, input_length=max_len))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "print(model.summary())\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer= Stochastic_Gradient_Descent,metrics=['accuracy', Precision(), Recall()])\n",
        "# Train model\n",
        "batch_size = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "402d6b63-3bf3-48cf-b590-163908ae68ae",
        "_uuid": "1f2778a3-1caf-4927-aef5-bdef1048457c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T13:57:14.165737Z",
          "iopub.status.busy": "2021-06-15T13:57:14.16538Z",
          "iopub.status.idle": "2021-06-15T14:03:03.293306Z",
          "shell.execute_reply": "2021-06-15T14:03:03.2925Z",
          "shell.execute_reply.started": "2021-06-15T13:57:14.165698Z"
        },
        "id": "oRRZRkzqDvzt",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a9c439ee-2fc6-4255-9f7a-c501db01d088",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 32)            160000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 50, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 25, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179,939\n",
            "Trainable params: 179,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1710/1710 [==============================] - 189s 108ms/step - loss: 0.9648 - accuracy: 0.5237 - precision: 0.6016 - recall: 0.2841 - val_loss: 0.8371 - val_accuracy: 0.6031 - val_precision: 0.6443 - val_recall: 0.4835\n",
            "Epoch 2/20\n",
            "1710/1710 [==============================] - 191s 112ms/step - loss: 0.7345 - accuracy: 0.6597 - precision: 0.6869 - recall: 0.6050 - val_loss: 0.6760 - val_accuracy: 0.6932 - val_precision: 0.7135 - val_recall: 0.6588\n",
            "Epoch 3/20\n",
            "1710/1710 [==============================] - 162s 95ms/step - loss: 0.6456 - accuracy: 0.6970 - precision: 0.7166 - recall: 0.6696 - val_loss: 0.6293 - val_accuracy: 0.7061 - val_precision: 0.7238 - val_recall: 0.6832\n",
            "Epoch 4/20\n",
            "1710/1710 [==============================] - 147s 86ms/step - loss: 0.6191 - accuracy: 0.7055 - precision: 0.7273 - recall: 0.6756 - val_loss: 0.6089 - val_accuracy: 0.7112 - val_precision: 0.7320 - val_recall: 0.6906\n",
            "Epoch 5/20\n",
            "1710/1710 [==============================] - 141s 83ms/step - loss: 0.6044 - accuracy: 0.7125 - precision: 0.7399 - recall: 0.6729 - val_loss: 0.5972 - val_accuracy: 0.7284 - val_precision: 0.7559 - val_recall: 0.6784\n",
            "Epoch 6/20\n",
            "1710/1710 [==============================] - 142s 83ms/step - loss: 0.5898 - accuracy: 0.7277 - precision: 0.7541 - recall: 0.6770 - val_loss: 0.5797 - val_accuracy: 0.7454 - val_precision: 0.7684 - val_recall: 0.6950\n",
            "Epoch 7/20\n",
            "1710/1710 [==============================] - 135s 79ms/step - loss: 0.5693 - accuracy: 0.7581 - precision: 0.7789 - recall: 0.7063 - val_loss: 0.5550 - val_accuracy: 0.7865 - val_precision: 0.8014 - val_recall: 0.7422\n",
            "Epoch 8/20\n",
            "1710/1710 [==============================] - 123s 72ms/step - loss: 0.5465 - accuracy: 0.7875 - precision: 0.8018 - recall: 0.7496 - val_loss: 0.5371 - val_accuracy: 0.8052 - val_precision: 0.8156 - val_recall: 0.7789\n",
            "Epoch 9/20\n",
            "1710/1710 [==============================] - 107s 63ms/step - loss: 0.5270 - accuracy: 0.8049 - precision: 0.8157 - recall: 0.7783 - val_loss: 0.5195 - val_accuracy: 0.8144 - val_precision: 0.8237 - val_recall: 0.7892\n",
            "Epoch 10/20\n",
            "1710/1710 [==============================] - 102s 60ms/step - loss: 0.5102 - accuracy: 0.8169 - precision: 0.8261 - recall: 0.7958 - val_loss: 0.5007 - val_accuracy: 0.8267 - val_precision: 0.8329 - val_recall: 0.8112\n",
            "Epoch 11/20\n",
            "1710/1710 [==============================] - 103s 60ms/step - loss: 0.4971 - accuracy: 0.8258 - precision: 0.8341 - recall: 0.8084 - val_loss: 0.4931 - val_accuracy: 0.8306 - val_precision: 0.8368 - val_recall: 0.8125\n",
            "Epoch 12/20\n",
            "1710/1710 [==============================] - 93s 55ms/step - loss: 0.4834 - accuracy: 0.8331 - precision: 0.8408 - recall: 0.8179 - val_loss: 0.4764 - val_accuracy: 0.8325 - val_precision: 0.8373 - val_recall: 0.8247\n",
            "Epoch 13/20\n",
            "1710/1710 [==============================] - 105s 61ms/step - loss: 0.4709 - accuracy: 0.8398 - precision: 0.8471 - recall: 0.8257 - val_loss: 0.4631 - val_accuracy: 0.8454 - val_precision: 0.8500 - val_recall: 0.8345\n",
            "Epoch 14/20\n",
            "1710/1710 [==============================] - 91s 53ms/step - loss: 0.4624 - accuracy: 0.8443 - precision: 0.8511 - recall: 0.8307 - val_loss: 0.4522 - val_accuracy: 0.8489 - val_precision: 0.8532 - val_recall: 0.8393\n",
            "Epoch 15/20\n",
            "1710/1710 [==============================] - 111s 65ms/step - loss: 0.4517 - accuracy: 0.8489 - precision: 0.8560 - recall: 0.8370 - val_loss: 0.4471 - val_accuracy: 0.8485 - val_precision: 0.8535 - val_recall: 0.8410\n",
            "Epoch 16/20\n",
            "1710/1710 [==============================] - 105s 61ms/step - loss: 0.4435 - accuracy: 0.8524 - precision: 0.8593 - recall: 0.8402 - val_loss: 0.4440 - val_accuracy: 0.8532 - val_precision: 0.8580 - val_recall: 0.8431\n",
            "Epoch 17/20\n",
            "1710/1710 [==============================] - 109s 64ms/step - loss: 0.4376 - accuracy: 0.8557 - precision: 0.8623 - recall: 0.8442 - val_loss: 0.4316 - val_accuracy: 0.8582 - val_precision: 0.8622 - val_recall: 0.8496\n",
            "Epoch 18/20\n",
            "1710/1710 [==============================] - 98s 57ms/step - loss: 0.4299 - accuracy: 0.8589 - precision: 0.8655 - recall: 0.8473 - val_loss: 0.4253 - val_accuracy: 0.8619 - val_precision: 0.8664 - val_recall: 0.8532\n",
            "Epoch 19/20\n",
            "1710/1710 [==============================] - 111s 65ms/step - loss: 0.4236 - accuracy: 0.8614 - precision: 0.8680 - recall: 0.8508 - val_loss: 0.4222 - val_accuracy: 0.8615 - val_precision: 0.8660 - val_recall: 0.8546\n",
            "Epoch 20/20\n",
            "1710/1710 [==============================] - 109s 64ms/step - loss: 0.4181 - accuracy: 0.8648 - precision: 0.8717 - recall: 0.8540 - val_loss: 0.4216 - val_accuracy: 0.8639 - val_precision: 0.8687 - val_recall: 0.8542\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(training_x, training_y, validation_data=(X_validation, y_validation),batch_size=batch_size, epochs=epochs, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f657ab51-e63e-47b3-8995-f13d79c570cd",
        "_uuid": "844d703e-882a-47c6-a3ba-b4622aa98626",
        "id": "1hK9ekmXDvzt",
        "trusted": true
      },
      "source": [
        "### Model Accuracy & Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3310bf9e-95ff-4d89-8e64-0f677054bddd",
        "_uuid": "42e7ee95-8192-4410-9c47-9f950a7a870e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T14:03:03.296973Z",
          "iopub.status.busy": "2021-06-15T14:03:03.296693Z",
          "iopub.status.idle": "2021-06-15T14:03:07.916302Z",
          "shell.execute_reply": "2021-06-15T14:03:07.915513Z",
          "shell.execute_reply.started": "2021-06-15T14:03:03.296947Z"
        },
        "id": "oTXZPChUDvzt",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "cfe6ec23-d4dd-4cb2-a6d8-9cde6eeb1798",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy  : 0.8567\n",
            "Precision : 0.8617\n",
            "Recall    : 0.8472\n",
            "F1 Score  : 0.8544\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(testing_x, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "45f9ed85-ee6e-4012-b40d-33455fdb8474",
        "_uuid": "21d1d657-02fc-4db4-8ea1-fee1327b76c1",
        "id": "ydcBCyc4Dvzt",
        "trusted": true
      },
      "source": [
        "### Model Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2aa7fd7a-c5e5-430a-8f4a-79c331e2486e",
        "_uuid": "f2225ada-4e4c-4b47-82b2-0b43b28dfb40",
        "id": "vMg1PfhTDvzu",
        "trusted": true
      },
      "source": [
        "### Model save and load for the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "567c602f-0579-4257-8f6b-7b6039fa6729",
        "_uuid": "7005da8f-1988-4e7b-a34d-f1355fe504f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-15T14:03:11.880904Z",
          "iopub.status.busy": "2021-06-15T14:03:11.880629Z",
          "iopub.status.idle": "2021-06-15T14:03:11.916253Z",
          "shell.execute_reply": "2021-06-15T14:03:11.915216Z",
          "shell.execute_reply.started": "2021-06-15T14:03:11.880862Z"
        },
        "id": "bCtanQL0Dvzu",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b715ff62-97b2-43b0-cff7-194959c20c93",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://83d185e4-6681-4bc7-88f0-8dc59ac087da/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://83d185e4-6681-4bc7-88f0-8dc59ac087da/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feec5a4e8d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feec5a596d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# Save the model architecture & the weights\n",
        "\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/files/sentiment_model','wb') as f:\n",
        "    pickle.dump(model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80ff55f2-b918-4dea-84a6-d0260c65a0fa",
        "_uuid": "bcfae6c2-a987-443b-a3d4-46722dca3827",
        "execution": {
          "iopub.execute_input": "2021-06-15T14:03:11.917916Z",
          "iopub.status.busy": "2021-06-15T14:03:11.917567Z",
          "iopub.status.idle": "2021-06-15T14:03:12.400898Z",
          "shell.execute_reply": "2021-06-15T14:03:12.400148Z",
          "shell.execute_reply.started": "2021-06-15T14:03:11.917862Z"
        },
        "id": "4cxCqV6wDvzu",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('sentiment_model','rb') as f:\n",
        "   model = pickle.load(f)\n",
        "def predict_class(text):\n",
        "    '''Function to predict sentiment class of the passed text'''\n",
        "    \n",
        "    sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
        "    max_len=50\n",
        "    \n",
        "    # Transforms text to a sequence of integers using a toke object\n",
        "    xt = toke.texts_to_sequences(text)\n",
        "    # Pad sequences to the same length\n",
        "    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n",
        "    # Do the prediction using the loaded model\n",
        "    yt = model.predict(xt).argmax(axis=1)\n",
        "    # Print the predicted sentiment\n",
        "    print('The predicted sentiment is', sentiment_classes[yt[0]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "twitter-sentiment-analysis-lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
